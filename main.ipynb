{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary functions from the module\n",
    "from mturk_helpers import *\n",
    "\n",
    "# Load environment variables and initialize MTurk client\n",
    "load_dotenv()  # This loads the environment variables from .env\n",
    "aws_access_key_id = os.environ.get('AWS_ACCESS_KEY_ID')\n",
    "aws_secret_access_key = os.environ.get('AWS_SECRET_ACCESS_KEY')\n",
    "region_name = 'us-east-1'\n",
    "endpoint_url = 'https://mturk-requester.us-east-1.amazonaws.com'\n",
    "\n",
    "mturk = boto3.client(\n",
    "    'mturk',\n",
    "    endpoint_url=endpoint_url,\n",
    "    region_name=region_name,\n",
    "    aws_access_key_id=aws_access_key_id,\n",
    "    aws_secret_access_key=aws_secret_access_key,\n",
    ")\n",
    "\n",
    "# Print account balance\n",
    "print(mturk.get_account_balance()['AvailableBalance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing and XML HIT creation\n",
    "input_directory = '../dataset_txt_format/'\n",
    "output_directory = './HITS_N'\n",
    "process_directory_in_chunks(input_directory, output_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Qualification creation\n",
    "feltalternativer = {\n",
    "    \"alder\": [\"18-24\", \"25-34\", \"35-44\", \"45-54\", \"55-64\", \"65+\"],\n",
    "    \"kjønn\": [\"Mann\", \"Kvinne\", \"Ikke-binær\", \"Foretrekker å ikke si\"],\n",
    "    \"yrke\": [\"Student\", \"Lærer\", \"Ingeniør\", \"Kunstner\", \"Annet\"],\n",
    "    \"arbeidsstatus\": [\"Heltid\", \"Deltid\", \"Arbeidsledig\", \"Pensjonert\", \"Annet\"],\n",
    "    \"interesser\": [\"Sport\", \"Teknologi\", \"Kunst\", \"Vitenskap\", \"Reise\", \"Annet\"],\n",
    "    \"hobbyer\": [\"Lesing\", \"Spilling\", \"Matlaging\", \"Fjellturer\", \"Håndarbeid\", \"Annet\"],\n",
    "    \"nyhetslesevaner\": [\"Daglig\", \"Ukentlig\", \"Månedlig\", \"Sjelden\", \"Aldri\"],\n",
    "    \"foretrukne nyhetskategorier\": [\"Politikk\", \"Økonomi\", \"Underholdning\", \"Sport\", \"Teknologi\", \"Annet\"],\n",
    "    \"Norsk språkferdigheter\": [\"Flytende\", \"Mellomnivå\", \"Grunnleggende\", \"Ingen\"],\n",
    "}\n",
    "\n",
    "free_text_fields = []\n",
    "personalia_test_xml = create_question_xml(feltalternativer, free_text_fields)\n",
    "answer_key_xml = create_answer_key_xml(feltalternativer)\n",
    "\n",
    "qualification_type_id_2 = create_qualification_type(\n",
    "    mturk_client=mturk,\n",
    "    name=\"NorwAI Norwegian Turk Personalia Qualification Preapproval v4\",\n",
    "    description=\"Denne kvalifikasjonsteksten er for å kartlegge våre arbeidere og vurdere deres kunnskaper i norsk og interesser\",\n",
    "    test=personalia_test_xml,\n",
    "    answer_key=answer_key_xml,\n",
    "    duration=1800  # Duration in seconds (30 minutes)\n",
    ")\n",
    "\n",
    "print(f\"Created Qualification Type ID: {qualification_type_id_2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve and list all qualifications made\n",
    "qualifications = list_my_qualifications(mturk)\n",
    "for qual in qualifications:\n",
    "    print(f\"ID: {qual['QualificationTypeId']}, Name: {qual['Name']}, Description: {qual['Description']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HIT deployment\n",
    "max_files_to_process = 148\n",
    "starting_point = 0\n",
    "all_xml_files = [f for f in sorted(os.listdir(output_directory)) if f.endswith('.xml')]\n",
    "for xml_file in all_xml_files[starting_point:max_files_to_process]:\n",
    "    xml_file_path = os.path.join(output_directory, xml_file)\n",
    "    try:\n",
    "        hit_id = create_hit_with_xml_file(xml_file_path, mturk, qualification_type_id_2)\n",
    "        print(f\"Created HIT with ID: {hit_id}\")\n",
    "        preview_link = f\"https://worker.mturk.com/mturk/preview?groupId={hit_id}\"\n",
    "        print(f\"Preview your HIT: {preview_link}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while creating HIT for {xml_file}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Approve qualifications manually\n",
    "approve_qualifications(mturk, qualification_type_id_2, 'mturk_qualification_personalia_second_experiment.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve HIT assignments to a dataframe\n",
    "fetch_all_hits(mturk, datetime.datetime(2024, 5, 18, tzinfo=timezone.utc), 'mturk_cache/fetched_hits.json')\n",
    "results_df = get_hit_results(mturk, 'mturk_cache/fetched_hits.json', 'mturk_cache/hit_data.json')\n",
    "results_df\n",
    "\n",
    "# Extract questions and match with XML files\n",
    "folders = [output_directory]\n",
    "xml_questions = {}\n",
    "for folder in folders:\n",
    "    for filename in os.listdir(folder):\n",
    "        if filename.endswith('.xml'):\n",
    "            question = extract_questions_from_xml(os.path.join(folder, filename))\n",
    "            xml_questions[tuple(question)] = folder + \"/\" + filename\n",
    "\n",
    "results_df['QuestionText'] = results_df['Question'].apply(lambda x: tuple(extract_texts_from_xml(x)))\n",
    "results_df['QuestionXML'] = results_df['Question'].apply(lambda x: xml_questions[tuple(extract_texts_from_xml(x))])\n",
    "\n",
    "# Expire all active HITs\n",
    "#expire_all_active_hits(mturk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results to a CSV file\n",
    "now = datetime.datetime.now()\n",
    "dt_string = now.strftime(\"%d-%m-%Y %H-%M-%S\")\n",
    "folder_name = \"HIT_results\"\n",
    "os.makedirs(folder_name, exist_ok=True)\n",
    "file_name = f\"contains_dataset_and_not_contains_hit_results_all_with_questions_{dt_string}.csv\"\n",
    "results_df.to_csv(os.path.join(folder_name, file_name), index=False)\n",
    "print(f\"Results exported to {file_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format the dataframe into readable txt files\n",
    "output_dir = './ParsedNotFilteredHITS'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "for index, row in results_df.iterrows():\n",
    "    question_text = parse_question_xml(row['Question'])\n",
    "    answer_text, passed = parse_answer_xml(row['Answer'])\n",
    "    if passed < 0:\n",
    "        print(f\"Worker {row['WorkerId']} did not pass all questions for HIT {row['HITId']}\")\n",
    "        continue\n",
    "\n",
    "    json_data = {\n",
    "        \"WorkerId\": row[\"WorkerId\"],\n",
    "        \"HITId\": row[\"HITId\"],\n",
    "        \"AssignmentId\": row[\"AssignmentId\"],\n",
    "        \"AssignmentStatus\": row.get(\"AssignmentStatus\", \"\"),\n",
    "        \"AcceptTime\": row.get(\"AcceptTime\", \"\"),\n",
    "        \"SubmitTime\": row.get(\"SubmitTime\", \"\"),\n",
    "        \"Duration\": row.get(\"Duration\", \"\"),\n",
    "        \"QuestionsAndAnswers\": []\n",
    "    }\n",
    "\n",
    "    text_content = \"\"\n",
    "    for key, value in json_data.items():\n",
    "        if key != \"QuestionsAndAnswers\":\n",
    "            text_content += f\"{key}: {value}\\n\"\n",
    "\n",
    "    for q in question_text:\n",
    "        q_index = q['Title'].split()[-1]\n",
    "        related_answers = [a for a in answer_text if a['Question ID'].startswith(f\"text{q_index}_\")]\n",
    "        qa_pairs = {\n",
    "            \"Title\": q['Title'],\n",
    "            \"QuestionText\": q['Text'],\n",
    "            \"Answers\": related_answers\n",
    "        }\n",
    "        json_data[\"QuestionsAndAnswers\"].append(qa_pairs)\n",
    "        text_content += f\"\\nTitle: {q['Title']}\\nQuestion Text: {q['Text']}\\n\"\n",
    "        for a in related_answers:\n",
    "            text_content += f\"- {a['Question ID']}: {a['Answer']}\\n\"\n",
    "\n",
    "    json_file_path = os.path.join(output_dir, f\"{row['AssignmentId']}.json\")\n",
    "    with open(json_file_path, 'w', encoding='utf-8') as json_file:\n",
    "        json.dump(json_data, json_file, indent=4)\n",
    "\n",
    "    txt_file_path = os.path.join(output_dir, f\"{row['AssignmentId']}.txt\")\n",
    "    with open(txt_file_path, 'w', encoding='utf-8') as txt_file:\n",
    "        txt_file.write(text_content)\n",
    "\n",
    "print(\"Files saved in directory:\", output_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Approve or reject HIT assignments\n",
    "from HITOrganizer import HITOrganizer\n",
    "from BanFilter import BanFilter\n",
    "from AssignmentFilter import AssignmentFilter\n",
    "\n",
    "hit_organizer = HITOrganizer(\"ParsedNotFilteredHITS\", \"UserProfiles3\")\n",
    "assignment_filter = AssignmentFilter('ParsedNotFilteredHITS')\n",
    "rejected_assignment_ids = assignment_filter.filter_assignments()\n",
    "workers_to_ban = BanFilter('ParsedNotFilteredHITS').get_worker_ids()\n",
    "\n",
    "approved_hits = results_df[~results_df['AssignmentId'].isin(rejected_assignment_ids)]\n",
    "approved_hits = approved_hits[approved_hits['AssignmentStatus'] == 'Submitted']\n",
    "approved_hits_list = approved_hits['AssignmentId'].tolist()\n",
    "\n",
    "for assignment_id in rejected_assignment_ids:\n",
    "    reject_hit(mturk, assignment_id, hit_organizer)\n",
    "\n",
    "for assignment_id in approved_hits_list:\n",
    "    approve_hit(mturk, assignment_id, hit_organizer)\n",
    "\n",
    "for worker in workers_to_ban:\n",
    "    ban_worker(mturk, worker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redeploy missing assignments\n",
    "questions_data = retrieve_and_count_questions(mturk, rejected_assignment_ids)\n",
    "#questions_data = retrieve_and_count_questions_from_cache(mturk, rejected_assignment_ids, 'mturk_cache/fetched_hits.json')\n",
    "\n",
    "for question_tuple in questions_data:\n",
    "    question_string = str(question_tuple)\n",
    "    matching_xml = results_df[results_df['QuestionText'] == question_string]['QuestionXML']\n",
    "    if not matching_xml.empty:\n",
    "        questions_data[question_tuple]['xml_file'] = matching_xml.iloc[0]\n",
    "    else:\n",
    "        print(f\"XML data not found for question tuple: {question_tuple}\")\n",
    "\n",
    "sample_question_data = questions_data[next(iter(questions_data))]\n",
    "sample_question_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "additional_assignments = 0\n",
    "for question, data in questions_data.items():\n",
    "    if data['total_count'] < 2:\n",
    "        additional_assignments += 2 - data['total_count']\n",
    "        counter += 1\n",
    "\n",
    "print(f\"Number of questions with less than 3 assignments: {counter}\")\n",
    "print(f\"Total additional assignments needed: {additional_assignments}\")\n",
    "\n",
    "create_consolidated_additional_hits(mturk, questions_data, qualification_type_id_2)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
